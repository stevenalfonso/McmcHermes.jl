var documenterSearchIndex = {"docs":
[{"location":"#McmcHermes.jl","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"","category":"section"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"A documentation for the McmcHermes package.","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"McmcHermes is a pure-Julia implementation of Metropolis Hasting Algorithm under an MIT license. McmcHermes will help you if you want to estimate model parameters or sample a probability density distribution.","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"","category":"page"},{"location":"#Installation","page":"McmcHermes.jl","title":"Installation","text":"","category":"section"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"using Pkg\nPkg.add(\"McmcHermes\")","category":"page"},{"location":"#Basic-Usage","page":"McmcHermes.jl","title":"Basic Usage","text":"","category":"section"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"note: Note\nThis guide assumes that you already have define your likelihood, prior and the logarithm of the posterior probability as in the example below.","category":"page"},{"location":"#Sampling","page":"McmcHermes.jl","title":"Sampling","text":"","category":"section"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"If you want to draw samples from the following distribution:","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"P(x) = frac1sqrt2 pi sigma_1 e^left- frac(x - mu_1)^22 sigma_1^2right + frac1sqrt2 pi sigma_2 e^left- frac(x - mu_2)^22 sigma_2^2right","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"You would do something like:","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"using McmcHermes\n\nfunction pdf(X::Number, params::Vector)\n    s1, s2, mu1, mu2 = params[1], params[2], params[3], params[4]\n    return 1 / (sqrt(2 * pi) * s1) * exp( -0.5*((X - mu1)/s1)^2 ) + 1 / (sqrt(2 * pi) * s2) * exp( -0.5*((X - mu2)/s2)^2 )\nend\n\nfunction gaussian_function(X::Vector, params::Vector)\n    x_values = collect(range(minimum(X), maximum(X), length=length(X)))\n    s1, s2, mu1, mu2 = params[1], params[2], params[3], params[4]\n    return 0.5 ./ (sqrt(2 * pi) .* s1) .* exp.(-0.5*((x_values .- mu1)./s1).^2) .+ 0.5 ./ (sqrt(2 * pi) .* s2) .* exp.(-0.5*((x_values .- mu2)./s2).^2)\nend\n\nparams = [3, 1.5, -5, 5]\ninterval = [-20, 20]\nsampling = McmcHermes.sampler(pdf, 10000, interval, params)\n\nx_values = Vector{Float64}(range(interval[1], interval[2], 100))\n\nhistogram(sampling, xlabel=L\"samples\", ylabel=L\"p(x)\", xguidefontsize=12, color=:gray, yguidefontsize=12, normalize=:pdf, show=true, label=\"samples\")\nplot!(x_values, gaussian_function(x_values, params), lw=3, size=(500,400), label=\"Function\", lc=:orange, show=true)","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"(Image: samples)","category":"page"},{"location":"#Parameter-estimation","page":"McmcHermes.jl","title":"Parameter estimation","text":"","category":"section"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"To estimate parameters mu and sigma from a gaussian distribution. First, you need some data","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"using Distributions, Plots, LaTeXStrings, DataFrames\n\nmu, sigma = 10, 2 # truths\nl_b, u_b = 0, 20\nd = Truncated(Normal(mu, sigma), l_b, u_b)\nN = 1000\ndata = rand(d, N)\n\nhistogram(data, legend=false, size=(300,300), xlabel=\"data\", show=true)","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"(Image: data)","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"Now, define likelihood and prior","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"function log_likelihood(X::Vector, parameters::Vector)\n    mu, sigma = parameters[1], parameters[2]\n    y = 1 ./ (sqrt(2 * pi) .* sigma) .* exp.( -0.5 * ((X .- mu)./sigma).^2 )\n    return sum(log.(y))\nend\n\nfunction log_prior(parameters::Vector)\n    mu, sigma = parameters[1], parameters[2]\n    if 5.0 < mu < 15.0 && 0.0 < sigma < 4.0\n        return 0.0\n    end\n    return -Inf\nend\n\nfunction log_probability(X::Vector, parameters::Vector)\n    lp = log_prior(parameters)\n    if !isfinite(lp)\n        return -Inf\n    end\n    return lp + log_likelihood(X, parameters)\nend","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"Then, define the number of walkers, iterations, dimension of the parameter space and the initial guess.","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"using McmcHermes\n\nmu, sigma = 10, 2\ninitparams = Vector{Float64}([mu, sigma])\n\nn_iter, n_walkers = 5000, 30\nn_dim = 2\nseed = rand(n_walkers, n_dim) * 1e-4 .+ transpose(initparams)\n\nchains = McmcHermes.run_mcmc(log_probability, data, seed, n_iter, n_walkers, n_dim, a=0.01)\n\nprintln(size(chains)) # (5000, 30, 2)","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"The convergence of the chains can be validated by the Gelman-Rubin's diagnostic:","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"println(\"Gelman Rubin Diagnostic: \", McmcHermes.get_gelman_rubin(chains)) # 1.0206366055","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"Finally, plot the chains.","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"labels = Tuple([L\"\\mu\", L\"\\sigma\"])\nx = 1:size(chains)[1]\np = []\nfor ind in 1:n_dim\n    push!(p, plot(x, [chains[:,i,ind] for i in 1:size(chains)[2]], legend=false, \n    lc=:black, lw=1, ylabel=labels[ind], alpha = 0.1, xticks=false))\nend\n\nplot(p[1], p[2], layout = (2,1))\nplot!(size=(600,200), xlims = (0, size(chains)[1]), show=true)","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"(Image: chains)","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"Chains can also be plotted in a corner. To do so, get the flat chain","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"flat_chains = McmcHermes.get_flat_chain(chains, burn_in=100, thin=10)\nprintln(size(flat_chains)) # (14901, 2)\nmean_posterior = quantile(flat_chains[:, 1], 0.5) # 10.0273672\nstd_posterior = quantile(flat_chains[:, 2], 0.5) # 1.9998453\n\nusing PairPlots, CairoMakie\n\ntable = (; x=flat_chains[:,1], y=flat_chains[:,2],)\nfig = pairplot(table, labels = Dict(:x => L\"\\mu\", :y => L\"\\sigma\"))","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"<img src=\"./assets/corner.png\" alt=\"corner\" width=\"200\"/>","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"Develop by J. Alfonso.","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"","category":"page"},{"location":"","page":"McmcHermes.jl","title":"McmcHermes.jl","text":"Modules = [McmcHermes]","category":"page"}]
}
